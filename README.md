# Graph_NN
 
## notes
A common precursor in solving many of these problems is node representation learning: learning to map individual nodes to fixed-size real-valued vectors (called ‘representations’ or ‘embeddings’).

https://distill.pub/2021/understanding-gnns/

Each iteration can be thought of as the equivalent of a ‘layer’ in standard neural networks.

Then, the graph Laplacian L is the square n×n matrix defined as: L=D−A.

Although it encodes precisely the same information as the adjacency matrix A

